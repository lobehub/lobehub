---
title: Using GitHub Models in LobeChat
description: >-
  Learn how to configure and use GitHub's API Key in LobeChat to start
  conversations and interactions.
tags:
  - LobeChat
  - GitHub
  - GitHub Models
  - API Key
  - Web UI
---

# Using GitHub Models in LobeChat

<Image cover src={'https://github.com/user-attachments/assets/3050839a-cb16-485d-8bae-1bc2f9ade632'} />

[GitHub Models](https://github.com/marketplace/models) is a new feature recently launched by GitHub, designed to provide developers with a free platform to access and experiment with various AI models. GitHub Models offers an interactive sandbox environment where users can test different model parameters and prompts to observe the model's responses. The platform supports a range of advanced language models, including OpenAI's GPT-4o, Meta's Llama 3.1, and Mistral's Large 2, covering a wide spectrum of use cases from large language models to task-specific models.

This guide will walk you through how to use GitHub Models within LobeChat.

## GitHub Models Rate Limits

Currently, usage of the Playground and free API is subject to limits on requests per minute, daily requests, tokens per request, and concurrent requests. If you hit a rate limit, you’ll need to wait for it to reset before making additional requests. Rate limits vary depending on the model type (low, high, or embedding models). For details on model types, refer to the GitHub Marketplace.

<Image alt={'GitHub Models Rate Limits'} inStep src={'https://github.com/user-attachments/assets/21c52e2a-b2f8-4de8-a5d4-cf3444608db7'} />

<Callout type="note">
  These limits are subject to change. For the most up-to-date information, please refer to the [official GitHub documentation](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits).
</Callout>

---

## GitHub Models Configuration Guide

<Steps>
  ### Step 1: Obtain a GitHub Access Token

  - Log in to GitHub and navigate to the [Personal Access Tokens](https://github.com/settings/tokens) page.
  - Create and configure a new access token.

  <Image alt={'Create Access Token'} inStep src={'https://github.com/user-attachments/assets/8570db14-dac6-4279-ab71-04a072c15490'} />

  - Copy and securely save the generated token from the result page.

  <Image alt={'Save Access Token'} inStep src={'https://github.com/user-attachments/assets/3c1a492d-a3d4-4570-9e74-785c2942ca41'} />

  <Callout type={"warning"}>
    - During the GitHub Models testing phase, you must apply to join the [waitlist](https://github.com/marketplace/models/waitlist/join) to gain access.

    ```
    - Be sure to store your access token securely, as it will only be shown once. If you lose it, you’ll need to generate a new one.
    ```
  </Callout>

  ### Step 2: Configure GitHub Models in LobeChat

  - Open the `Settings` panel in LobeChat.
  - Under `AI Providers`, locate the `GitHub` configuration section.

  <Image alt={'Enter Access Token'} inStep src={'https://github.com/user-attachments/assets/a00f06cc-da7c-41e8-a4d5-d4b675a22673'} />

  - Paste the access token you obtained earlier.
  - Choose a GitHub model for your AI assistant to start chatting.

  <Image alt={'Select GitHub Model and Start Chatting'} inStep src={'https://github.com/user-attachments/assets/aead3c6c-891e-47c3-9f34-bdc33875e0c2'} />
</Steps>

And that’s it! You’re now ready to start using GitHub-provided models in LobeChat for conversations and interactions.
