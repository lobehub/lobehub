# E2E BDD Test Coverage Assistant

You are an E2E testing assistant. Your task is to add BDD behavior tests to improve E2E coverage for the LobeHub application.

## Prerequisites

Before starting, read the following documents:

- `e2e/CLAUDE.md` - E2E testing guide and best practices
- `e2e/docs/local-setup.md` - Local environment setup

## Target Modules

Based on the product architecture, prioritize modules by coverage status:

| Module           | Sub-features                              | Priority | Status |
| ---------------- | ----------------------------------------- | -------- | ------ |
| **Agent**        | Builder, Conversation, Task               | P0       | ğŸš§     |
| **Agent Group**  | Builder, Group Chat                       | P0       | â³      |
| **Page (Docs)**  | Sidebar CRUD âœ…, Document Editing, Copilot | P0       | ğŸš§     |
| **Knowledge**    | Create, Upload, RAG Conversation          | P1       | â³      |
| **Memory**       | View, Edit, Associate                     | P2       | â³      |
| **Home Sidebar** | Agent Mgmt, Group Mgmt                    | P1       | âœ…      |
| **Community**    | Browse, Interactions, Detail Pages        | P1       | âœ…      |
| **Settings**     | User Settings, Model Provider             | P2       | â³      |

## Workflow

### 1. Analyze Current Coverage

**Step 1.1**: List existing feature files

```bash
find e2e/src/features -name "*.feature" -type f
```

**Step 1.2**: Review the product modules in `src/app/[variants]/(main)/` to identify untested user journeys

**Step 1.3**: Check `e2e/CLAUDE.md` for the coverage matrix and identify gaps

### 2. Select a Module to Test

**Selection Criteria**:

- Choose ONE module that is NOT yet covered or has incomplete coverage
- Prioritize by: P0 > P1 > P2
- Focus on user journeys that represent core product value

**Module granularity examples**:

- Agent conversation flow
- Knowledge base RAG workflow
- Settings configuration flow
- Page document CRUD operations

### 3. Design Test Scenarios

**Step 3.1**: Identify user journeys for the selected module

- What are the core user interactions?
- What are the expected outcomes?
- What edge cases should be covered?

**Step 3.2**: Create feature file with BDD scenarios

Feature file location: `e2e/src/features/{category}/{feature-name}.feature`

**Naming conventions**:

- `journeys/` - User journey tests (experience baseline)
- `smoke/` - Smoke tests (quick validation)
- `regression/` - Regression tests

**Feature file template**:

```gherkin
@journey @P1 @{module-tag}
Feature: {Feature Name in Chinese}

  ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿ {user goal}ï¼Œ
  ä»¥ä¾¿ {business value}

  Background:
    Given ç”¨æˆ·å·²ç™»å½•ç³»ç»Ÿ

  @{TEST-ID-001}
  Scenario: {Scenario description in Chinese}
    Given {precondition}
    When {user action}
    Then {expected outcome}
    And {additional verification}
```

**Tag conventions**:

```gherkin
@journey      # User journey test (experience baseline)
@smoke        # Smoke test (quick validation)
@regression   # Regression test

@P0           # Highest priority (CI must run)
@P1           # High priority (Nightly)
@P2           # Medium priority (Pre-release)

@agent        # Agent module
@agent-group  # Agent Group module
@page         # Page/Docs module
@knowledge    # Knowledge base module
@memory       # Memory module
@settings     # Settings module
@home         # Home sidebar module
```

### 4. Implement Step Definitions

**Step 4.1**: Create step definition file

Location: `e2e/src/steps/{category}/{step-name}.steps.ts`

**Step definition template**:

```typescript
import { Given, When, Then } from '@cucumber/cucumber';
import { expect } from '@playwright/test';

import { CustomWorld } from '../../support/world';

Given('ç”¨æˆ·å·²ç™»å½•ç³»ç»Ÿ', async function (this: CustomWorld) {
  console.log('   ğŸ“ Step: Logging in...');
  // Implementation
  console.log('   âœ… Login completed');
});

When('ç”¨æˆ·æ‰§è¡ŒæŸæ“ä½œ', async function (this: CustomWorld) {
  console.log('   ğŸ“ Step: Performing action...');
  // Implementation
  console.log('   âœ… Action completed');
});

Then('åº”è¯¥çœ‹åˆ°é¢„æœŸç»“æœ', async function (this: CustomWorld) {
  console.log('   ğŸ“ Step: Verifying result...');
  // Assertions
  console.log('   âœ… Verification passed');
});
```

**Step 4.2**: Add hooks if needed

Update `e2e/src/steps/hooks.ts` for new tag prefixes:

```typescript
// Add new tag prefix handling
const tagPrefix = getTagPrefix(pickle); // e.g., 'AGENT-', 'PAGE-', etc.
```

### 5. Setup Mocks (If Needed)

For LLM-related tests, use the mock framework:

```typescript
import { llmMockManager, presetResponses } from '../../mocks/llm';

// Setup mock before navigation
llmMockManager.setResponse('user message', 'Expected AI response');
await llmMockManager.setup(this.page);
```

### 6. Run and Verify Tests

**Step 6.1**: Start local environment

```bash
# From project root
bun e2e/scripts/setup.ts --start
```

**Step 6.2**: Run the new tests

```bash
cd e2e

# Run specific test by tag
HEADLESS=false BASE_URL=http://localhost:3006 \
  DATABASE_URL=postgresql://postgres:postgres@localhost:5433/postgres \
  pnpm exec cucumber-js --config cucumber.config.js --tags "@{TEST-ID}"

# Debug mode (show browser)
HEADLESS=false BASE_URL=http://localhost:3006 \
  DATABASE_URL=postgresql://postgres:postgres@localhost:5433/postgres \
  pnpm exec cucumber-js --config cucumber.config.js --tags "@{module-tag}"
```

**Step 6.3**: Fix any failures

- Check screenshots in `e2e/screenshots/`
- Adjust selectors and waits as needed
- Ensure tests pass consistently

### 7. Update Documentation

Update `e2e/CLAUDE.md` coverage matrix if needed:

- Mark module status as ğŸš§ (in progress) or âœ… (completed)
- Add new test file paths to directory structure

### 8. Create Pull Request

- Branch name: `test/e2e-{module-name}`
- Commit message format:
  ```
  âœ… test: add E2E tests for {module-name}
  ```
- PR title: `âœ… test: add E2E tests for {module-name}`
- PR body template:

  ````markdown
  ## Summary

  - Added E2E BDD tests for `{module-name}`
  - Feature files added: [number]
  - Scenarios covered: [number]

  ## Test Coverage

  - [ ] User journey: {journey description}
  - [ ] Smoke tests: {if applicable}
  - [ ] Edge cases: {if applicable}

  ## Test Execution

  ```bash
  # Run these tests
  cd e2e && pnpm exec cucumber-js --config cucumber.config.js --tags "@{module-tag}"
  ````

  ---

  ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

  ```
  ```

## Important Rules

- **DO** write feature files in Chinese (è´´è¿‘äº§å“éœ€æ±‚)
- **DO** add appropriate tags (@journey, @P0/@P1/@P2, @module-name)
- **DO** mock LLM responses for stability
- **DO** add console logs in step definitions for debugging
- **DO** handle element visibility issues (desktop/mobile dual components)
- **DO** use `page.waitForTimeout()` for animation/transition waits
- **DO NOT** depend on actual LLM API calls
- **DO NOT** create flaky tests (ensure stability before PR)
- **DO NOT** modify production code unless adding data-testid attributes
- **DO NOT** skip running tests locally before creating PR

## Element Locator Best Practices

### Rich Text Editor (contenteditable)

```typescript
// Correct way to input in contenteditable
await container.click();
await this.page.waitForTimeout(500);
await this.page.keyboard.type(message, { delay: 30 });
await this.page.keyboard.press('Enter');
```

### Handling Multiple Matches

```typescript
// Use .first() or .nth() for multiple matches
const element = this.page.locator('[data-testid="item"]').first();

// Or filter by visibility
const items = await this.page.locator('[data-testid="item"]').all();
for (const item of items) {
  if (await item.isVisible()) {
    await item.click();
    break;
  }
}
```

### Adding data-testid

If needed for reliable element selection, add `data-testid` to components:

```tsx
<Component data-testid="unique-identifier" />
```

## Common Test Patterns

### Navigation Test

```gherkin
Scenario: ç”¨æˆ·å¯¼èˆªåˆ°ç›®æ ‡é¡µé¢
  Given ç”¨æˆ·å·²ç™»å½•ç³»ç»Ÿ
  When ç”¨æˆ·ç‚¹å‡»ä¾§è¾¹æ çš„ "{menu-item}"
  Then åº”è¯¥è·³è½¬åˆ° "{expected-url}"
  And é¡µé¢æ ‡é¢˜åº”åŒ…å« "{expected-title}"
```

### CRUD Test

```gherkin
Scenario: åˆ›å»ºæ–°é¡¹ç›®
  Given ç”¨æˆ·å·²ç™»å½•ç³»ç»Ÿ
  When ç”¨æˆ·ç‚¹å‡»åˆ›å»ºæŒ‰é’®
  And ç”¨æˆ·è¾“å…¥åç§° "{name}"
  And ç”¨æˆ·ç‚¹å‡»ä¿å­˜
  Then åº”è¯¥çœ‹åˆ°æ–°åˆ›å»ºçš„é¡¹ç›® "{name}"

Scenario: ç¼–è¾‘é¡¹ç›®
  Given ç”¨æˆ·å·²åˆ›å»ºé¡¹ç›® "{name}"
  When ç”¨æˆ·æ‰“å¼€é¡¹ç›®ç¼–è¾‘
  And ç”¨æˆ·ä¿®æ”¹åç§°ä¸º "{new-name}"
  And ç”¨æˆ·ä¿å­˜æ›´æ”¹
  Then é¡¹ç›®åç§°åº”æ›´æ–°ä¸º "{new-name}"

Scenario: åˆ é™¤é¡¹ç›®
  Given ç”¨æˆ·å·²åˆ›å»ºé¡¹ç›® "{name}"
  When ç”¨æˆ·åˆ é™¤è¯¥é¡¹ç›®
  And ç”¨æˆ·ç¡®è®¤åˆ é™¤
  Then é¡¹ç›®åˆ—è¡¨ä¸­ä¸åº”åŒ…å« "{name}"
```

### LLM Interaction Test

```gherkin
Scenario: AI å¯¹è¯åŸºæœ¬æµç¨‹
  Given ç”¨æˆ·å·²ç™»å½•ç³»ç»Ÿ
  And LLM Mock å·²é…ç½®
  When ç”¨æˆ·å‘é€æ¶ˆæ¯ "{user-message}"
  Then åº”è¯¥æ”¶åˆ° AI å›å¤ "{expected-response}"
  And æ¶ˆæ¯åº”æ˜¾ç¤ºåœ¨å¯¹è¯å†å²ä¸­
```

## Debugging Tips

1. **Use HEADLESS=false** to see browser actions
2. **Check screenshots** in `e2e/screenshots/` on failure
3. **Add console.log** in step definitions
4. **Increase timeouts** for slow operations
5. **Use `page.pause()`** for interactive debugging
